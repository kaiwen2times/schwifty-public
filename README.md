# Voice

### Bridging the gap between hard of hearing students and classroom learning through real-time speech-to-text

## Project Team:

Amina Bintory 
David Lor 
Long Pham
Kaiwen Zheng

## Need Statement

The National Technical Institute for the Deaf (NTID) at Rochester Institute of Technology (RIT), NY, has over 1,300 deaf or hard-of-hearing students enrolled as of 2016. These students are admitted to 200 programs offered by nine of the other colleges at RIT. These students attend the same classes as the regular students at RIT. In order to communicate with these students, NTID uses methods like sign language, finger spelling, printed/visual aids, and Web-based instructional materials. In a classroom setting, support to these students is provided through sources such as note-taking, tutoring, and interpreters. Students are hired to take notes during class time and submit them to the NTID office. The office scans the notes and uploads them onto a site which can be accessed by the hard of hearing students. Interpreters with different skill sets are hired to translate the lecture to the hard of hearing students through sign language in real-time in class. The hard of hearing students need to watch the professor teach as well as comprehend what the interpreter is saying at the same time. They try to understand the notes taken by another student with a different intellect and a different hand-writing. This means that the content and handwriting will vary based on the individual taking the notes and may not be understood by hard-of-hearing students. A system is needed to simplify the way the notes are handed to the hard-of-hearing students. This system should increase efficiency, must be accurate, and must be easily accessible to the deaf students. This eliminates a communication barrier between the professor-interpreter-student as well as reading of a different handwriting or missing important notes. 

## Objective Statement

The objective of this project is to develop a service to convert speech to text in real time and display the information to the deaf or hard-of-hearing students so they can get the lecture material immediately directly from the professor instead of using a third party. They can also take notes side-by-side on the same display instead of having to rely on note-takers. This eliminates the need for note-takers and interpreters. All the lecture material is directly passed to the student in real time and gives the students a chance to interact with the professor as they can understand what is going on in class.

## Description

The service designed in this project automates the process of live captioning for deaf or hard-of-hearing students to understand what is going on in class and actively participate in class. For instance, if the pace of the professor is fast and the interpreter is missing a lot of the information, the student will not understand the material being taught. Also, if the note-taker is not taking notes of key material, then the student might miss out on important information. Some key material might not be important to the note-taker but might be important for the deaf student. A student might have questions in class for the professor but will not have them answered. These issues can be solved by this service. The lecture material taught by the professor gets captured by a microphone. The speech is transferred wirelessly to a microcontroller. The microcontroller runs a web browser and uploads the audio to the website. Then the website converts the speech to text and display it to the user with short latency. User has the option to download the notes to his or her computer. This way the professor can teach the material without slowing down, and there is no interpreter missing information or note-taker missing notes. The notes will be available instantly as well. 

## Posting Issues

You are welcome to create an issue [here](https://github.com/kaiwen2times/schwifty-public/issues)

